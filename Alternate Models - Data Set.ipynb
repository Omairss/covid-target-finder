{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'tensorflow' from '/miniconda/lib/python3.6/site-packages/tensorflow/__init__.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "import lxml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras\n",
    "import importlib\n",
    "import time\n",
    "import traceback\n",
    "\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from ast import literal_eval\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, Dropout, Conv1D, Flatten, MaxPooling1D,\\\n",
    "                        AveragePooling1D, Concatenate, LeakyReLU, Embedding,\\\n",
    "                        GlobalMaxPooling1D,GlobalAveragePooling1D,GaussianNoise,BatchNormalization,Add,ZeroPadding1D\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "\n",
    "\n",
    "importlib.reload(tensorflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "failed initializing StreamExecutor for CUDA device ordinal 0: Internal: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_OUT_OF_MEMORY: out of memory; total memory reported: 11996954624",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-ec20110cb113>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mdevices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, target, graph, config)\u001b[0m\n\u001b[1;32m   1549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \"\"\"\n\u001b[0;32m-> 1551\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m     \u001b[0;31m# NOTE(mrry): Create these on first `__enter__` to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_graph_context_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, target, graph, config)\u001b[0m\n\u001b[1;32m    674\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m       \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_NewSessionRef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m       \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: failed initializing StreamExecutor for CUDA device ordinal 0: Internal: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_OUT_OF_MEMORY: out of memory; total memory reported: 11996954624"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "with tf.Session() as sess:\n",
    "    devices = sess.list_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions / Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "class PlotLosses(tensorflow.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.i = 0\n",
    "        self.x = []\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        \n",
    "        self.fig = plt.figure()\n",
    "        \n",
    "        self.logs = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        self.logs.append(logs)\n",
    "        self.x.append(self.i)\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        self.i += 1\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        plt.plot(self.x, self.losses, label=\"loss\")\n",
    "        plt.plot(self.x, self.val_losses, label=\"val_loss\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "        plt.plot(range(len(global_history)), global_history, label = 'Accuracy - Global')\n",
    "        plt.plot(range(len(global_val_history)), global_val_history, label = 'Accuracy - Global - Va;')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "plot_losses = PlotLosses()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data - chunk size : 100\n",
      "Data read complete : 0.8506441116333008s\n"
     ]
    }
   ],
   "source": [
    "chunk_size = 100\n",
    "\n",
    "drugbank_reader = pd.read_csv('data/intermediate/interactions_preprocessed.csv', chunksize = chunk_size, iterator = True, converters={\"target_gene_encoded_padded\": \\\n",
    "                                                                                     lambda x: np.array(x.strip(\"[]\").replace(\"'\",\"\").split(\", \")),\n",
    "                                                                                    \"drug_fingerprint_encoded_padded\": \\\n",
    "                                                                                    lambda x: np.array(x.strip(\"[]\").replace(\"'\",\"\").split(\", \"))})\n",
    "\n",
    "\n",
    "print (\"Reading data - chunk size : \" + str(chunk_size) )\n",
    "start = time.time()\n",
    "drugbank = drugbank_reader.__next__()\n",
    "end = time.time()\n",
    "print (\"Data read complete : \" + str(end - start) + \"s\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_db = drugbank[['drug_id', 'gene_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "996520dae0864ecfa952f41f93768306",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "drug_dict = {}\n",
    "gene_dict = {}\n",
    "\n",
    "for drugbank in tqdm(drugbank_reader):\n",
    "    \n",
    "    compressed_db = drugbank[['drug_id', 'gene_id']]\n",
    "    \n",
    "    for i in range(len(compressed_db)):\n",
    "        \n",
    "        try:\n",
    "            drug = compressed_db['drug_id'].values[i]\n",
    "            gene = compressed_db['gene_id'].values[i]\n",
    "\n",
    "            try:\n",
    "                drug_dict[drug].add(gene)\n",
    "            except: \n",
    "                drug_dict[drug] = set()\n",
    "                drug_dict[drug].add(gene)\n",
    "\n",
    "            try:\n",
    "                gene_dict[gene].add(drug)\n",
    "            except: \n",
    "                gene_dict[gene] = set()\n",
    "                gene_dict[gene].add(drug)\n",
    "        \n",
    "        except Exception as e: \n",
    "            print (\"Exception : \" + str(e))\n",
    "            traceback.print_exc()\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number Of Unique Drugs : 6215\n",
      "Number Of Unique Genes : 3774\n"
     ]
    }
   ],
   "source": [
    "print (\"Number Of Unique Drugs : \" + str(len(drug_dict.keys())))\n",
    "print (\"Number Of Unique Genes : \" + str(len(gene_dict.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_to_gene_count = np.zeros((len(drug_dict.keys()), 2))\n",
    "gene_to_drug_count = np.zeros((len(gene_dict.keys()), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_keys = list(drug_dict.keys())\n",
    "gene_keys = list(gene_dict.keys())\n",
    "\n",
    "for d in range(len(drug_keys)):\n",
    "    drug_to_gene_count[d][0] = d\n",
    "    drug_to_gene_count[d][1] = len(drug_dict[drug_keys[d]])\n",
    "drug_to_gene_count = pd.DataFrame(drug_to_gene_count)\n",
    "drug_to_gene_count.columns = ['Drug Index', 'Number Of Genes']\n",
    "    \n",
    "for g in range(len(gene_keys)):\n",
    "    gene_to_drug_count[g][0] = g\n",
    "    gene_to_drug_count[g][1] = len(gene_dict[gene_keys[g]])\n",
    "gene_to_drug_count = pd.DataFrame(gene_to_drug_count)\n",
    "gene_to_drug_count.columns = ['Gene Index', 'Number Of Drugs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentile Split Of Drug -> Gene Interaction\n",
      "p1 : 1.0 Genes\n",
      "p25 : 2.0 Genes\n",
      "p50 : 6.0 Genes\n",
      "p75 : 12.0 Genes\n",
      "p99 : 160.0 Genes\n",
      "\n",
      "Percentile Split Of Gene -> Drug Interaction\n",
      "p1 : 1.0 Drugs\n",
      "p25 : 3.0 Drugs\n",
      "p50 : 8.0 Drugs\n",
      "p75 : 19.0 Drugs\n",
      "p99 : 290.39999999999964 Drugs\n"
     ]
    }
   ],
   "source": [
    "percentile_list = [1, 25, 50, 75, 99]\n",
    "print (\"Percentile Split Of Drug -> Gene Interaction\")\n",
    "for p in percentile_list: \n",
    "    print (\"p\" + str(p) + \" : \" + str(np.percentile(drug_to_gene_count['Number Of Genes'], p)) + \" Genes\")\n",
    "print (\"\") \n",
    "print (\"Percentile Split Of Gene -> Drug Interaction\")\n",
    "for p in percentile_list: \n",
    "    print (\"p\" + str(p) + \" : \" + str(np.percentile(gene_to_drug_count['Number Of Drugs'], p)) + \" Drugs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Lists Of Similar Genes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Method 1 : </b>\n",
    "\n",
    "Randomly Sample Genes To Build Lists Of Similar Genes\n",
    "\n",
    "This will contain genes overlapping multiple drugs. We could run this multiple times and produce multiple\n",
    "datasets to train the network on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number Of Similar Gene Lists With Length > 2 : 81\n",
      "p1 : 3.0 Similar Genes\n",
      "p25 : 3.0 Similar Genes\n",
      "p50 : 5.0 Similar Genes\n",
      "p75 : 13.0 Similar Genes\n",
      "p99 : 694.6000000000009 Similar Genes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "number_of_genes = len(gene_dict.keys())\n",
    "list_of_genes = []\n",
    "genes_considered = set()\n",
    "\n",
    "for i in range(1000):\n",
    "    \n",
    "    # Select A Random Gene Not Yet Selected\n",
    "    count = 0\n",
    "    break_flag = 0\n",
    "    while gene in genes_considered:\n",
    "        gene = gene_keys[np.random.randint(number_of_genes)]\n",
    "        count = count + 1 \n",
    "        # All Genes Have Been Considered\n",
    "        if count == len(gene_dict.keys()):\n",
    "            break_flag = 1\n",
    "            break\n",
    "    \n",
    "    if break_flag == 1: \n",
    "        break\n",
    "\n",
    "    similar_genes = []\n",
    "    \n",
    "    # For Each Drug That Works On This Gene\n",
    "    for drug in gene_dict[gene]:\n",
    "        \n",
    "        # Get Other Genes Affected By Drug\n",
    "        for other_gene in drug_dict[drug]:\n",
    "            \n",
    "            # Check If This Gene Already Belongs To Another Group\n",
    "            if other_gene not in genes_considered:\n",
    "                genes_considered.add(other_gene)\n",
    "                similar_genes.append(other_gene)\n",
    "            else: \n",
    "                continue\n",
    "    \n",
    "    list_of_genes.append(similar_genes)         \n",
    "\n",
    "\n",
    "gene_data_distribution = []\n",
    "gene_train_set = []\n",
    "min_threshold = 2\n",
    "for l in list_of_genes: \n",
    "    if len(l) > 2:\n",
    "        gene_train_set.append(l)\n",
    "        gene_data_distribution.append(len(l))\n",
    "        \n",
    "print (\"Number Of Similar Gene Lists With Length > \" + str(min_threshold) + \" : \" + str(len(gene_train_set)))\n",
    "for p in percentile_list: \n",
    "    print (\"p\" + str(p) + \" : \" + str(np.percentile(gene_data_distribution, p)) + \" Similar Genes\")\n",
    "print (\"\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Method 2 : </b>\n",
    "\n",
    "Pick out genes which are affected only by one drug. Then pick out other genes which are also affected \n",
    "by the same drug. \n",
    "\n",
    "In doing so, we ensure there is no overlap in similar genes across drugs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number Of Similar Gene Lists With Length > 2 : 116\n",
      "p1 : 3.0 Similar Genes\n",
      "p25 : 7.0 Similar Genes\n",
      "p50 : 14.0 Similar Genes\n",
      "p75 : 37.0 Similar Genes\n",
      "p99 : 153.09999999999997 Similar Genes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "list_of_genes = []\n",
    "genes_considered = set()\n",
    "single_drug_gene = []\n",
    "\n",
    "# Find All Genes That Are Affected Only By ONE Drug \n",
    "for gene in gene_dict.keys():\n",
    "    if len(gene_dict[gene]) == 1:\n",
    "        single_drug_gene.append(gene)\n",
    "\n",
    "# For Each Gene\n",
    "for gene in single_drug_gene:\n",
    "    \n",
    "    # Skip Gene If It's Already Part Of A Similar Set\n",
    "    if gene not in genes_considered: \n",
    "        \n",
    "        genes_considered.add(gene)\n",
    "        similar_genes = []\n",
    "\n",
    "        # Find The Drug That Affects It\n",
    "        drug = list(gene_dict[gene])[0]\n",
    "\n",
    "\n",
    "        # Find Other Genes This Drug Affects And Add It To Similar Genes\n",
    "        for other_gene in drug_dict[drug]:\n",
    "            similar_genes.append(other_gene)\n",
    "            genes_considered.add(other_gene)\n",
    "\n",
    "        list_of_genes.append(similar_genes)\n",
    "    \n",
    "    else: \n",
    "        continue\n",
    "\n",
    "gene_data_distribution = []\n",
    "gene_train_set = []\n",
    "min_threshold = 2\n",
    "for l in list_of_genes: \n",
    "    if len(l) > min_threshold:\n",
    "        gene_train_set.append(l)\n",
    "        gene_data_distribution.append(len(l))\n",
    "        \n",
    "print (\"Number Of Similar Gene Lists With Length > \" + str(min_threshold) + \" : \" + str(len(gene_train_set)))\n",
    "for p in percentile_list: \n",
    "    print (\"p\" + str(p) + \" : \" + str(np.percentile(gene_data_distribution, p)) + \" Similar Genes\")\n",
    "print (\"\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build List Of Similar Drugs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick out drugs which work only on one gene. Then pick out other drugs which also work on the same gene.\n",
    "\n",
    "In doing so, we ensure there is no overlap in similar drugs across genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number Of Similar Drug Lists With Lenght > 2 : 291\n",
      "p1 : 3.0 Similar Drugs\n",
      "p25 : 7.0 Similar Drugs\n",
      "p50 : 14.0 Similar Drugs\n",
      "p75 : 27.5 Similar Drugs\n",
      "p99 : 153.30000000000007 Similar Drugs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "list_of_drugs = []\n",
    "drugs_considered = set()\n",
    "single_gene_drug = []\n",
    "\n",
    "# Find All Drugs That Work Only On ONE Gene\n",
    "for drug in drug_dict.keys():\n",
    "    if len(drug_dict[drug]) == 1:\n",
    "        single_gene_drug.append(drug)\n",
    "        \n",
    "# For Each Drug\n",
    "for drug in single_gene_drug:\n",
    "    \n",
    "    # Skip Drug If It's Already Part Of A Similar Set\n",
    "    if drug not in drugs_considered: \n",
    "        \n",
    "        drugs_considered.add(drug)\n",
    "        similar_drugs = []\n",
    "\n",
    "        # Find The Gene That The Drug Works On\n",
    "        gene = list(drug_dict[drug])[0]\n",
    "\n",
    "\n",
    "        # Find Other Drugs That Work On This Gene\n",
    "        for other_drug in gene_dict[gene]:\n",
    "            similar_drugs.append(other_drug)\n",
    "            drugs_considered.add(other_drug)\n",
    "\n",
    "        list_of_drugs.append(similar_drugs)\n",
    "    \n",
    "    else: \n",
    "        continue\n",
    "        \n",
    "drug_data_distribution = []\n",
    "drug_train_set = []\n",
    "min_threshold = 2\n",
    "for l in list_of_drugs: \n",
    "    if len(l) > min_threshold:\n",
    "        drug_train_set.append(l)\n",
    "        drug_data_distribution.append(len(l))\n",
    "        \n",
    "print (\"Number Of Similar Drug Lists With Lenght > \" + str(min_threshold) + \" : \" + str(len(drug_train_set)))\n",
    "for p in percentile_list: \n",
    "    print (\"p\" + str(p) + \" : \" + str(np.percentile(drug_data_distribution, p)) + \" Similar Drugs\")\n",
    "print (\"\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
